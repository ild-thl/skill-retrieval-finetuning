{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain_core.documents import Document\n",
    "from typing import Dict, List, Set, Optional, Any, Tuple\n",
    "import json\n",
    "import requests\n",
    "from api_client import APIClient\n",
    "from api_config import APIConfig\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup evaluation data\n",
    "\n",
    "Only execute one of the following cells to either setup a GRETA or ESCO evalution dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for GRETA Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsfile = 'evalGretaModelResults.json'\n",
    "\n",
    "# load greata csv file to pandas dataframe GRETA-Kompetenzmodell_v2.csv\n",
    "greta_pd = pd.read_csv('../../data/GRETA/sources/GRETA-Kompetenzmodell_v2.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "# Create new column that combines the columns \"Kompetenzfacetten\", \"Kompetenzaspekte\", \"Kompetenzbereiche\", \"Kompetenzanforderungen\", \"Kompetenzbeschreibung\"\n",
    "# greta_pd['page_content'] = \"Kompetenz: \" + greta_pd['Kompetenzfacette'] + '/n geh√∂rt zu /n Kompetenzaspekt: ' + greta_pd['Kompetenzaspekt'] + ', Kompetenzbereich: ' + greta_pd['Kompetenzbereich'] + ',/n Kompetenzanforderungen: ' + greta_pd['Kompetenzanforderungen'] + ', Kompetenzbeschreibung: ' + greta_pd['Kompetenzbeschreibung']\n",
    "greta_pd['page_content'] = greta_pd['Kompetenzfacette'] + ',/nKompetenzanforderungen: ' + greta_pd['Kompetenzanforderungen']\n",
    "# Only get page_content and Kompetenzfacette columns\n",
    "greta_pd = greta_pd[['page_content', 'Kompetenzfacette']]\n",
    "# Rename Kompetenzfacette to title\n",
    "greta_pd = greta_pd.rename(columns={'Kompetenzfacette': 'title'})\n",
    "\n",
    "# Get the evaluation data\n",
    "with open('../../data/GRETA/validated_greta_240704.json', 'r', encoding='utf-8') as fIn:\n",
    "    data = json.load(fIn)\n",
    "\n",
    "# Load the data into the DataFrameLoader\n",
    "loader = DataFrameLoader(greta_pd, page_content_column=\"page_content\")\n",
    "documents = loader.load()\n",
    "corpus = {i: d['title'] for i, d in enumerate(greta_pd.to_dict('records'))}\n",
    "queries = {i: d['query'] for i, d in enumerate(data)}\n",
    "\n",
    "relevant_docs = {}\n",
    "for i, d in enumerate(data):\n",
    "    relevant_docs[i] = []\n",
    "    for doc in d['pos']:\n",
    "        for j, c in corpus.items():\n",
    "            if c == doc:\n",
    "                relevant_docs[i].append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup for ESCO Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get skill data for embedding\n",
    "resultsfile = 'results/evalESCOModelResultsESCOEval.json'\n",
    "\n",
    "# Load texts from json file\n",
    "skills = pd.read_csv(\"../../data/ESCO/sources/skills_as_documents_v120.csv\")\n",
    "\n",
    "skills['description'] = skills['description'].fillna('')\n",
    "skills['broaderHierarchyConcepts'] = skills['broaderHierarchyConcepts'].fillna('')\n",
    "skills['broaderSkills'] = skills['broaderSkills'].fillna('')\n",
    "skills['narrowerSkills'] = skills['narrowerSkills'].fillna('')\n",
    "skills['isEssentialForOccupations'] = skills['isEssentialForOccupations'].fillna('')\n",
    "skills['isOptionalForOccupations'] = skills['isOptionalForOccupations'].fillna('')\n",
    "skills['isEssentialForSkills'] = skills['isEssentialForSkills'].fillna('')\n",
    "skills['isOptionalForSkills'] = skills['isOptionalForSkills'].fillna('')\n",
    "\n",
    "# Create a new column that combines preferredLabel and description.\n",
    "skills['page_content'] = skills['preferredLabel'] + \": \" + skills['description']\n",
    "\n",
    "# Add a new column called 'taxonomy' with the value 'ESCO'.\n",
    "skills['taxonomy'] = 'ESCO'\n",
    "\n",
    "# remove row where page_content or title is empty\n",
    "skills = skills[skills['page_content'].notna()]\n",
    "skills = skills[skills['preferredLabel'].notna()]\n",
    "\n",
    "skills = skills[['page_content', 'preferredLabel']]\n",
    "# Are there rows with missing preferredLabel?\n",
    "# Rename Kompetenzfacette to title\n",
    "skills = skills.rename(columns={'preferredLabel': 'title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the evaluation data\n",
    "import json\n",
    "# with open('../../data/ESCO/archive/wisy_validated_240704.json', 'r', encoding='utf-8') as fIn:\n",
    "#     data = json.load(fIn)\n",
    "\n",
    "# Load the evaluation data\n",
    "with open('../../data/eval_split/eval_dataset.jsonl', 'r', encoding='utf-8') as f:\n",
    "    data = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build corpus (all available esco skill titles) and queries (from the eval dataset) and relevant docs (array of indices matching the esco skill from corpus based on the posiive labels per sample in eval dataset)\n",
    "corpus = {i: d['title'] for i, d in enumerate(skills.to_dict('records'))}\n",
    "queries = {i: d['query'] for i, d in enumerate(data)}\n",
    "# relevant_docs = {i: [corpus.index(doc) for doc in d['pos']] for i, d in enumerate(data)}\n",
    "relevant_docs = {}\n",
    "for i, d in enumerate(data):\n",
    "    relevant_docs[i] = []\n",
    "    for doc in d['pos']:\n",
    "        for j, c in corpus.items():\n",
    "            if c == doc or doc.startswith(f\"{c}: \"):\n",
    "                relevant_docs[i].append(j)\n",
    "\n",
    "# Build the documents for the vector store\n",
    "loader = DataFrameLoader(skills, page_content_column=\"page_content\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Retrieval Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    }
   ],
   "source": [
    "from retrieval_evaluator import RetrievalEvaluator\n",
    "evaluator = RetrievalEvaluator(queries, corpus, relevant_docs, store_docs=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APIConfig for evaluating skill prediction APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom formatters for different APIs\n",
    "\n",
    "def competence_analyser_request_formatter(query: str, top_k: int) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"\n",
    "    Format request for the competence analyser API v2/chatsearch endpoint\n",
    "    Returns (data, params) tuple\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"doc\": query,  # The course description goes into 'doc' field\n",
    "        \"taxonomies\": [\"ESCO\"],  # Focus on ESCO taxonomy for our evaluation\n",
    "        \"targets\": [\"learning_outcomes\"],  # We want learning outcomes\n",
    "        \"top_k\": top_k,\n",
    "        \"rerank\": True,  # Use reranking\n",
    "        \"finetuned\": True,  # Use fine-tuned models\n",
    "        \"trusted_score\": 0.0,  # Accept all scores, we'll filter later\n",
    "        \"score_cutoff\": 0.0,  # Accept all scores\n",
    "        \"strict\": 0,  # Get all top_k offers, without any cutoff\n",
    "        \"use_llm\": False,  # Don't use LLM extraction to keep it comparable\n",
    "        \"openai_api_key\": os.getenv(\"OPENAI_API_KEY\", \"\"),  # Use environment variable for OpenAI key\n",
    "        \"llm_validation\": False,  # Don't use LLM validation to keep it comparable\n",
    "    }\n",
    "    return data, None  # No URL parameters needed\n",
    "\n",
    "def competence_analyser_response_parser(response) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Parse response from the competence analyser API v2/chatsearch endpoint\n",
    "    Returns list of (skill_name, score) tuples\n",
    "    \"\"\"\n",
    "    result = response.json()\n",
    "    predictions = []\n",
    "    \n",
    "    # The v2 API returns a more complex structure\n",
    "    # We need to extract skills from learning_outcomes -> skills\n",
    "    if \"learning_outcomes\" in result and result[\"learning_outcomes\"]:\n",
    "        learning_outcomes = result[\"learning_outcomes\"]\n",
    "        if \"skills\" in learning_outcomes:\n",
    "            for skill in learning_outcomes[\"skills\"]:\n",
    "                if \"title\" in skill and \"score\" in skill:\n",
    "                    # Note: Higher scores are better in this API\n",
    "                    predictions.append((skill[\"title\"], float(skill[\"score\"])))\n",
    "    \n",
    "    # Sort by score descending (higher is better)\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    return predictions\n",
    "\n",
    "def generic_api_request_formatter(query: str, top_k: int) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"Generic formatter for simple APIs\"\"\"\n",
    "    data = {\"query\": query, \"top_k\": top_k}\n",
    "    return data, None\n",
    "\n",
    "def generic_api_response_parser(response) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Generic parser for simple API responses\"\"\"\n",
    "    result = response.json()\n",
    "    predictions = []\n",
    "\n",
    "def metadatagen_request_formatter(query: str, top_k: int) -> Tuple[Dict, Optional[Dict]]:\n",
    "    \"\"\"Format request for the MetadataGen API\"\"\"\n",
    "    data = {\n",
    "        \"name\": query,  # Use course name as the query\n",
    "        \"description\": \"This course covers the fundamentals of machine learning including supervised and unsupervised learning algorithms, neural networks, and practical applications in data science.\",\n",
    "        \"top_k\": top_k  # Limit results to top_k skills\n",
    "    }\n",
    "\n",
    "    return data, None  # No URL parameters needed\n",
    "\n",
    "def get_esco_skill_name(skill_uri: str, language: str = 'en', version: str = 'v1.2.0') -> str:\n",
    "    \"\"\"Fetch the ESCO skill name based on the skill ID and language\"\"\"\n",
    "    # https://ec.europa.eu/esco/api/resource/skill?uri=&language=\n",
    "    url = f\"https://ec.europa.eu/esco/api/resource/skill?uri={skill_uri}&language={language}&selectedVersion={version}\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result[\"preferredLabel\"][language] if \"preferredLabel\" in result and language in result[\"preferredLabel\"] else null\n",
    "    else:\n",
    "        print(f\"Error fetching skill name for {skill_uri}: {response.status_code} {response.text}\")\n",
    "        return null\n",
    "\n",
    "\n",
    "def metadatagen_response_parser(response) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Parse response from the MetadataGen API\"\"\"\n",
    "    result = response.json()\n",
    "    predictions = []\n",
    "    # The MetadataGen API returns a list of skills with concept URLs and names\n",
    "    if isinstance(result, list):\n",
    "        for index, item in enumerate(result):\n",
    "            if isinstance(item, dict) and \"name\" in item and \"conceptUrl\" in item:\n",
    "                skill_uri = item[\"conceptUrl\"]\n",
    "                # Here we assume descending scores based on index\n",
    "                score = 1.0 - (index / len(result))  # Normalize score to [0, 1]\n",
    "                de_skill_name = get_esco_skill_name(skill_uri, 'de', 'v1.2.0')\n",
    "                predictions.append((de_skill_name, score))\n",
    "            else:\n",
    "                # Handle unexpected item format\n",
    "                print(\"Unexpected item format in response:\", item)\n",
    "                continue\n",
    "    else:\n",
    "        # If the response is not a list, handle it gracefully\n",
    "        print(\"Unexpected response format:\", result)\n",
    "        return []\n",
    "    \n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)  # Sort by score descending\n",
    "    return predictions\n",
    "    \n",
    "    # Try different common response formats\n",
    "    if \"predictions\" in result:\n",
    "        for item in result[\"predictions\"]:\n",
    "            if isinstance(item, dict) and \"skill\" in item and \"score\" in item:\n",
    "                predictions.append((item[\"skill\"], float(item[\"score\"])))\n",
    "            elif isinstance(item, dict) and \"name\" in item and \"score\" in item:\n",
    "                predictions.append((item[\"name\"], float(item[\"score\"])))\n",
    "    elif \"skills\" in result and \"scores\" in result:\n",
    "        skills = result[\"skills\"]\n",
    "        scores = result[\"scores\"]\n",
    "        predictions = [(skill, float(score)) for skill, score in zip(skills, scores)]\n",
    "    elif isinstance(result, list):\n",
    "        for item in result:\n",
    "            if isinstance(item, dict):\n",
    "                if \"skill\" in item and \"score\" in item:\n",
    "                    predictions.append((item[\"skill\"], float(item[\"score\"])))\n",
    "                elif \"name\" in item and \"score\" in item:\n",
    "                    predictions.append((item[\"name\"], float(item[\"score\"])))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# API Configuration Examples\n",
    "# Customize these configurations based on your actual APIs\n",
    "\n",
    "# Your competence analyser API configuration\n",
    "COMPETENCE_ANALYSER_CONFIG = APIConfig(\n",
    "    name=\"competence_analyser\",\n",
    "    base_url=\"https://lab.dlc.sh/competence-analyser\",\n",
    "    endpoint=\"/v2/chatsearch\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    auth_token=None,  # Add your token if needed\n",
    "    request_format=\"json\",\n",
    "    response_format=\"json\",\n",
    "    max_requests_per_second=2.0,  # Be respectful to the API\n",
    "    timeout=60.0,  # Longer timeout for complex processing\n",
    "    custom_request_formatter=competence_analyser_request_formatter,\n",
    "    custom_response_parser=competence_analyser_response_parser\n",
    ")\n",
    "\n",
    "# MetadataGen API configuration\n",
    "METADATAGEN_API_CONFIG = APIConfig(\n",
    "    name=\"metadataGen\",\n",
    "    base_url=\"http://host.docker.internal\",\n",
    "    endpoint=\"/get_esco_suggestions\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    auth_token=None,  # Add their token if needed\n",
    "    request_format=\"json\",\n",
    "    response_format=\"json\",\n",
    "    max_requests_per_second=2.0,  # Be respectful to external APIs\n",
    "    timeout=45.0,\n",
    "    custom_request_formatter=metadatagen_request_formatter,\n",
    "    custom_response_parser=metadatagen_response_parser\n",
    ")\n",
    "\n",
    "# Additional API configurations can be added here\n",
    "API_CONFIGS = {\n",
    "    \"competence_analyser\": COMPETENCE_ANALYSER_CONFIG,\n",
    "    \"metadata_gen\": METADATAGEN_API_CONFIG,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "c:\\Users\\pasca\\code\\ISy\\WISY@KI\\skill-retrieval-eval\\scripts\\evaluation\\retrieval_evaluator.py:87: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing vector store containing 13938 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 196/196\r"
     ]
    }
   ],
   "source": [
    "modelresults[\"isy-finetuned\"] = evaluator(\"isy-thl/multilingual-e5-base-course-skill-tuned\", use_cached_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults[\"isy-finetuned-w-reranker\"] = evaluator(\"isy-thl/multilingual-e5-base-course-skill-tuned\", reranker_model_name=\"isy-thl/bge-reranker-base-course-skill-tuned\", use_cached_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults[\"all-MiniLM-L6-v2\"] = evaluator(\"sentence-transformers/all-MiniLM-L6-v2\", use_cached_db=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "c:\\Users\\pasca\\code\\ISy\\WISY@KI\\skill-retrieval-eval\\retrieval_evaluator.py:87: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing vector store containing 13938 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 196/196\r"
     ]
    }
   ],
   "source": [
    "modelresults[\"finetune_1\"] = evaluator(\"models/finetuned_esco_model_082249\", use_cached_db=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelresults[\"finetune_2\"] = evaluator(\"models/finetuned_esco_model_103730\", use_cached_db=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "c:\\Users\\pasca\\code\\ISy\\WISY@KI\\skill-retrieval-eval\\retrieval_evaluator.py:87: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing vector store containing 13938 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 95/95\r"
     ]
    }
   ],
   "source": [
    "modelresults[\"finetune_3_wisy_validated_eval\"] = evaluator(\"models/finetuned_esco_model_115640\", use_cached_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelresults[\"bge_base\"] = evaluator(\"BAAI/bge-base-en-v1.5\")\n",
    "# modelresults[\"bge_finetuned\"] = evaluator(\"bge_finetuned_no_sync\")\n",
    "# modelresults[\"bge_greta_finetuned\"] = evaluator(\"bge_greta_finetuned_no_sync\")\n",
    "# modelresults[\"bge_m3\"] = evaluator(\"BAAI/bge-m3\")\n",
    "# modelresults[\"bge_m3_greta_finetuned\"] = evaluator(\"bge_m3_greta_finetuned_no_sync\")\n",
    "# modelresults[\"bge_m3_finetuned\"] = evaluator(\"bge_m3_finetuned_no_sync\")\n",
    "# modelresults[\"snowflake-arctic-embed-l\"] = evaluator(\"Snowflake/snowflake-arctic-embed-l\")\n",
    "# modelresults[\"multilingual-e5-base\"] = evaluator(\"intfloat/multilingual-e5-base\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_e5_greta_finetuned\"] = evaluator(\"multilingual_e5_greta_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_e5_finetuned\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_e5_m3_finetuned\"] = evaluator(\"multilingual_e5_m3_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_finetuned_esco6000\"] = evaluator(\"multilingual_finetuned_esco6000_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"multilingual_finetuned_esco1500\"] = evaluator(\"multilingual_finetuned_esco1500_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"mixed_multilingual_finetuned\"] = evaluator(\"mixed_multilingual_finetuned_no_sync\", query_instruction=\"query: \", embed_instruction=\"passage: \")\n",
    "# modelresults[\"bge_reranker_finetuned\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", reranker_model_name=\"bge_reranker_finetuned_no_sync\")\n",
    "# modelresults[\"bge_reranker_greta_finetuned\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", reranker_model_name=\"bge_reranker_greta_finetuned_no_sync\", use_cached_db=True)\n",
    "# modelresults[\"bge_reranker_skillfit\"] = evaluator(\"multilingual_e5_finetuned_no_sync\", reranker_model_name=\"pascalhuerten/bge_reranker_skillfit\", use_cached_db=True)\n",
    "# modelresults[\"instructor-base\"] = evaluator(\"hkunlp/instructor-base\", use_cached_db=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Testing Section\n",
    "\n",
    "Now we can test APIs alongside the embedding models. Configure your API endpoints above and run the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API connectivity before running full evaluation\n",
    "def test_api_connectivity(api_config: APIConfig, test_query: str = \"Python programming\"):\n",
    "    \"\"\"Test if an API is accessible and returns valid responses\"\"\"\n",
    "    try:\n",
    "        client = APIClient(api_config)\n",
    "        predictions = client.predict(test_query, top_k=5)\n",
    "        \n",
    "        print(f\"‚úÖ API '{api_config.name}' is accessible\")\n",
    "        print(f\"   Base URL: {api_config.base_url}\")\n",
    "        print(f\"   Test query: '{test_query}'\")\n",
    "        print(f\"   Returned {len(predictions)} predictions:\")\n",
    "        \n",
    "        for i, (skill, score) in enumerate(predictions[:3], 1):\n",
    "            print(f\"   {i}. {skill} (score: {score:.4f})\")\n",
    "        \n",
    "        if len(predictions) > 3:\n",
    "            print(f\"   ... and {len(predictions) - 3} more\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API '{api_config.name}' failed connectivity test:\")\n",
    "        print(f\"   Error: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Test connectivity for all configured APIs\n",
    "print(\"Testing API connectivity...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "api_test_results = {}\n",
    "for api_name, api_config in API_CONFIGS.items():\n",
    "    print(f\"\\nTesting {api_name}:\")\n",
    "    api_test_results[api_name] = test_api_connectivity(api_config)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"API Connectivity Summary:\")\n",
    "for api_name, is_working in api_test_results.items():\n",
    "    status = \"‚úÖ Working\" if is_working else \"‚ùå Failed\"\n",
    "    print(f\"  {api_name}: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run API evaluations\n",
    "# Only run evaluations for APIs that passed connectivity tests\n",
    "for api_name, api_config in API_CONFIGS.items():\n",
    "    if api_name in modelresults:\n",
    "        print(f\"Skipping {api_name} - already evaluated\")\n",
    "        continue\n",
    "    print(f\"\\nüöÄ Starting evaluation for {api_name}...\")\n",
    "    try:\n",
    "        modelresults[api_name] = evaluator(api_config=api_config)\n",
    "        print(f\"‚úÖ Completed evaluation for {api_name}\")\n",
    "    except Exception as e:\n",
    "        # Print error and stack trace\n",
    "        print(f\"‚ùå Evaluation failed for {api_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        modelresults[api_name] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the results to a file or merge with existing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Read the existing data\n",
    "existingresults = {}\n",
    "if os.path.exists(resultsfile):\n",
    "    with open(resultsfile, 'r', encoding='utf-8') as fIn:\n",
    "        existingresults = json.load(fIn)\n",
    "# Merge the two dictionaries\n",
    "for model, results in modelresults.items():\n",
    "    existingresults[model] = results\n",
    "\n",
    "# Write the new dictionary back to the file\n",
    "with open(resultsfile, 'w', encoding='utf-8') as fOut:\n",
    "    json.dump(existingresults, fOut, indent=4)\n",
    "\n",
    "modelresults = existingresults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the results as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c6ed2_row0_col1, #T_c6ed2_row0_col5, #T_c6ed2_row0_col7, #T_c6ed2_row0_col8, #T_c6ed2_row0_col9, #T_c6ed2_row0_col12, #T_c6ed2_row0_col13, #T_c6ed2_row0_col15, #T_c6ed2_row1_col16, #T_c6ed2_row2_col2, #T_c6ed2_row2_col3, #T_c6ed2_row2_col4, #T_c6ed2_row2_col6, #T_c6ed2_row2_col10, #T_c6ed2_row2_col11, #T_c6ed2_row2_col14 {\n",
       "  background-color: rgb(175,227,145);\n",
       "}\n",
       "#T_c6ed2_row0_col2, #T_c6ed2_row0_col3, #T_c6ed2_row0_col4, #T_c6ed2_row0_col6, #T_c6ed2_row0_col10, #T_c6ed2_row0_col11, #T_c6ed2_row0_col14, #T_c6ed2_row2_col1, #T_c6ed2_row2_col5, #T_c6ed2_row2_col7, #T_c6ed2_row2_col8, #T_c6ed2_row2_col9, #T_c6ed2_row2_col12, #T_c6ed2_row2_col13, #T_c6ed2_row2_col15, #T_c6ed2_row2_col16 {\n",
       "  background-color: rgb(230,230,230);\n",
       "}\n",
       "#T_c6ed2_row0_col16, #T_c6ed2_row1_col1, #T_c6ed2_row1_col2, #T_c6ed2_row1_col3, #T_c6ed2_row1_col4, #T_c6ed2_row1_col5, #T_c6ed2_row1_col6, #T_c6ed2_row1_col7, #T_c6ed2_row1_col8, #T_c6ed2_row1_col9, #T_c6ed2_row1_col10, #T_c6ed2_row1_col11, #T_c6ed2_row1_col12, #T_c6ed2_row1_col13, #T_c6ed2_row1_col14, #T_c6ed2_row1_col15 {\n",
       "  background-color: rgb(110, 235, 55);\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c6ed2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c6ed2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c6ed2_level0_col1\" class=\"col_heading level0 col1\" >accuracy@1</th>\n",
       "      <th id=\"T_c6ed2_level0_col2\" class=\"col_heading level0 col2\" >accuracy@3</th>\n",
       "      <th id=\"T_c6ed2_level0_col3\" class=\"col_heading level0 col3\" >accuracy@5</th>\n",
       "      <th id=\"T_c6ed2_level0_col4\" class=\"col_heading level0 col4\" >accuracy@10</th>\n",
       "      <th id=\"T_c6ed2_level0_col5\" class=\"col_heading level0 col5\" >precision@1</th>\n",
       "      <th id=\"T_c6ed2_level0_col6\" class=\"col_heading level0 col6\" >precision@3</th>\n",
       "      <th id=\"T_c6ed2_level0_col7\" class=\"col_heading level0 col7\" >precision@5</th>\n",
       "      <th id=\"T_c6ed2_level0_col8\" class=\"col_heading level0 col8\" >precision@10</th>\n",
       "      <th id=\"T_c6ed2_level0_col9\" class=\"col_heading level0 col9\" >recall@1</th>\n",
       "      <th id=\"T_c6ed2_level0_col10\" class=\"col_heading level0 col10\" >recall@3</th>\n",
       "      <th id=\"T_c6ed2_level0_col11\" class=\"col_heading level0 col11\" >recall@5</th>\n",
       "      <th id=\"T_c6ed2_level0_col12\" class=\"col_heading level0 col12\" >recall@10</th>\n",
       "      <th id=\"T_c6ed2_level0_col13\" class=\"col_heading level0 col13\" >ndcg@10</th>\n",
       "      <th id=\"T_c6ed2_level0_col14\" class=\"col_heading level0 col14\" >mrr@10</th>\n",
       "      <th id=\"T_c6ed2_level0_col15\" class=\"col_heading level0 col15\" >map@100</th>\n",
       "      <th id=\"T_c6ed2_level0_col16\" class=\"col_heading level0 col16\" >avg_time_per_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c6ed2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c6ed2_row0_col0\" class=\"data row0 col0\" >finetuned_esco_model_082249</td>\n",
       "      <td id=\"T_c6ed2_row0_col1\" class=\"data row0 col1\" >0.617347</td>\n",
       "      <td id=\"T_c6ed2_row0_col2\" class=\"data row0 col2\" >0.785714</td>\n",
       "      <td id=\"T_c6ed2_row0_col3\" class=\"data row0 col3\" >0.852041</td>\n",
       "      <td id=\"T_c6ed2_row0_col4\" class=\"data row0 col4\" >0.918367</td>\n",
       "      <td id=\"T_c6ed2_row0_col5\" class=\"data row0 col5\" >0.617347</td>\n",
       "      <td id=\"T_c6ed2_row0_col6\" class=\"data row0 col6\" >0.374150</td>\n",
       "      <td id=\"T_c6ed2_row0_col7\" class=\"data row0 col7\" >0.288776</td>\n",
       "      <td id=\"T_c6ed2_row0_col8\" class=\"data row0 col8\" >0.177551</td>\n",
       "      <td id=\"T_c6ed2_row0_col9\" class=\"data row0 col9\" >0.341205</td>\n",
       "      <td id=\"T_c6ed2_row0_col10\" class=\"data row0 col10\" >0.538962</td>\n",
       "      <td id=\"T_c6ed2_row0_col11\" class=\"data row0 col11\" >0.635216</td>\n",
       "      <td id=\"T_c6ed2_row0_col12\" class=\"data row0 col12\" >0.736297</td>\n",
       "      <td id=\"T_c6ed2_row0_col13\" class=\"data row0 col13\" >0.649722</td>\n",
       "      <td id=\"T_c6ed2_row0_col14\" class=\"data row0 col14\" >0.718788</td>\n",
       "      <td id=\"T_c6ed2_row0_col15\" class=\"data row0 col15\" >0.576427</td>\n",
       "      <td id=\"T_c6ed2_row0_col16\" class=\"data row0 col16\" >0.148500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6ed2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c6ed2_row1_col0\" class=\"data row1 col0\" >finetuned_esco_model_115640</td>\n",
       "      <td id=\"T_c6ed2_row1_col1\" class=\"data row1 col1\" >0.668367</td>\n",
       "      <td id=\"T_c6ed2_row1_col2\" class=\"data row1 col2\" >0.877551</td>\n",
       "      <td id=\"T_c6ed2_row1_col3\" class=\"data row1 col3\" >0.933673</td>\n",
       "      <td id=\"T_c6ed2_row1_col4\" class=\"data row1 col4\" >0.974490</td>\n",
       "      <td id=\"T_c6ed2_row1_col5\" class=\"data row1 col5\" >0.668367</td>\n",
       "      <td id=\"T_c6ed2_row1_col6\" class=\"data row1 col6\" >0.442177</td>\n",
       "      <td id=\"T_c6ed2_row1_col7\" class=\"data row1 col7\" >0.333673</td>\n",
       "      <td id=\"T_c6ed2_row1_col8\" class=\"data row1 col8\" >0.203061</td>\n",
       "      <td id=\"T_c6ed2_row1_col9\" class=\"data row1 col9\" >0.346821</td>\n",
       "      <td id=\"T_c6ed2_row1_col10\" class=\"data row1 col10\" >0.618558</td>\n",
       "      <td id=\"T_c6ed2_row1_col11\" class=\"data row1 col11\" >0.728171</td>\n",
       "      <td id=\"T_c6ed2_row1_col12\" class=\"data row1 col12\" >0.842873</td>\n",
       "      <td id=\"T_c6ed2_row1_col13\" class=\"data row1 col13\" >0.733287</td>\n",
       "      <td id=\"T_c6ed2_row1_col14\" class=\"data row1 col14\" >0.783275</td>\n",
       "      <td id=\"T_c6ed2_row1_col15\" class=\"data row1 col15\" >0.654642</td>\n",
       "      <td id=\"T_c6ed2_row1_col16\" class=\"data row1 col16\" >0.152288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c6ed2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c6ed2_row2_col0\" class=\"data row2 col0\" >isy-finetuned</td>\n",
       "      <td id=\"T_c6ed2_row2_col1\" class=\"data row2 col1\" >0.586735</td>\n",
       "      <td id=\"T_c6ed2_row2_col2\" class=\"data row2 col2\" >0.846939</td>\n",
       "      <td id=\"T_c6ed2_row2_col3\" class=\"data row2 col3\" >0.892857</td>\n",
       "      <td id=\"T_c6ed2_row2_col4\" class=\"data row2 col4\" >0.943878</td>\n",
       "      <td id=\"T_c6ed2_row2_col5\" class=\"data row2 col5\" >0.586735</td>\n",
       "      <td id=\"T_c6ed2_row2_col6\" class=\"data row2 col6\" >0.387755</td>\n",
       "      <td id=\"T_c6ed2_row2_col7\" class=\"data row2 col7\" >0.276531</td>\n",
       "      <td id=\"T_c6ed2_row2_col8\" class=\"data row2 col8\" >0.165816</td>\n",
       "      <td id=\"T_c6ed2_row2_col9\" class=\"data row2 col9\" >0.317975</td>\n",
       "      <td id=\"T_c6ed2_row2_col10\" class=\"data row2 col10\" >0.570886</td>\n",
       "      <td id=\"T_c6ed2_row2_col11\" class=\"data row2 col11\" >0.639788</td>\n",
       "      <td id=\"T_c6ed2_row2_col12\" class=\"data row2 col12\" >0.725300</td>\n",
       "      <td id=\"T_c6ed2_row2_col13\" class=\"data row2 col13\" >0.635635</td>\n",
       "      <td id=\"T_c6ed2_row2_col14\" class=\"data row2 col14\" >0.720264</td>\n",
       "      <td id=\"T_c6ed2_row2_col15\" class=\"data row2 col15\" >0.553081</td>\n",
       "      <td id=\"T_c6ed2_row2_col16\" class=\"data row2 col16\" >0.161767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dcb9f59d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare results as a table\n",
    "import pandas as pd\n",
    "\n",
    "# compare results as a table\n",
    "import pandas as pd\n",
    "\n",
    "def get_result_df(modelresults):\n",
    "    results = pd.DataFrame({\n",
    "        'Model': list(modelresults.keys()),\n",
    "        'accuracy@1': [modelresults[model]['accuracy@1'] for model in modelresults],\n",
    "        'accuracy@3': [modelresults[model]['accuracy@3'] for model in modelresults],\n",
    "        'accuracy@5': [modelresults[model]['accuracy@5'] for model in modelresults],\n",
    "        'accuracy@10': [modelresults[model]['accuracy@10'] for model in modelresults],\n",
    "        'precision@1': [modelresults[model]['precision@1'] for model in modelresults],\n",
    "        'precision@3': [modelresults[model]['precision@3'] for model in modelresults],\n",
    "        'precision@5': [modelresults[model]['precision@5'] for model in modelresults],\n",
    "        'precision@10': [modelresults[model]['precision@10'] for model in modelresults],\n",
    "        'recall@1': [modelresults[model]['recall@1'] for model in modelresults],\n",
    "        'recall@3': [modelresults[model]['recall@3'] for model in modelresults],\n",
    "        'recall@5': [modelresults[model]['recall@5'] for model in modelresults],\n",
    "        'recall@10': [modelresults[model]['recall@10'] for model in modelresults],\n",
    "        'ndcg@10': [modelresults[model]['ndcg@10'] for model in modelresults],\n",
    "        'mrr@10': [modelresults[model]['mrr@10'] for model in modelresults],\n",
    "        'map@100': [modelresults[model]['map@100'] for model in modelresults],\n",
    "        # 'avg_time_per_1000_chars': [modelresults[model]['avg_time_per_1000_chars'] for model in modelresults],\n",
    "        'avg_time_per_query': [modelresults[model]['avg_time_per_query'] for model in modelresults],\n",
    "        # 'total_time': [modelresults[model]['total_time'] for model in modelresults]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Filter modelresults for these modelnames in that order\n",
    "filtered_results = modelresults\n",
    "# filter_models = ['instructor-base', 'instructor-large', 'instructor-skillfit', 'bge_base', 'bge_greta_finetuned', 'bge_finetuned', 'bge_m3', 'bge_m3_greta_finetuned', 'bge_m3_finetuned', 'multilingual-e5-base', 'multilingual_e5_greta_finetuned', 'multilingual_e5_finetuned', 'mle5f+bge_reranker_skillfit', 'mle5f+bge_reranker_greta_finetuned', 'mle5f+bge_reranker_finetuned']\n",
    "# filter_models = ['intfloat/multilingual-e5-base', 'isy-thl/multilingual-e5-base-course-skill-tuned', 'isy-thl/bge-reranker-base-course-skill-tuned']\n",
    "# filtered_results = {model: modelresults[model] for model in filter_models}\n",
    "results = get_result_df(filtered_results)\n",
    "\n",
    "# filter_models = ['instructor-base', 'instructor-large', 'instructor-skillfit', 'bge_base', 'bge_greta_finetuned', 'bge_finetuned', 'bge_m3', 'bge_m3_greta_finetuned', 'bge_m3_finetuned', 'multilingual-e5-base', 'multilingual_e5_greta_finetuned', 'multilingual_e5_finetuned', 'bge_reranker_skillfit', 'bge_reranker_greta_finetuned', 'bge_reranker_finetuned']\n",
    "\n",
    "\n",
    "# def highlight_max(s):\n",
    "#     '''\n",
    "#     Highlight the maximum in a Series yellow.\n",
    "#     '''\n",
    "#     is_max = s == s.max()\n",
    "#     return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "def grade_by_rank(s):\n",
    "    # skip if column Model\n",
    "    if s.name == 'Model':\n",
    "        return ['' for v in s]\n",
    "    # Get count of values\n",
    "    count = len(s)\n",
    "    reverse = False\n",
    "    if 'time' in s.name:\n",
    "        reverse = True\n",
    "    ordered = s.sort_values(ascending=reverse)\n",
    "    # Define a lighter green RGB\n",
    "    good = (120, 225, 60)\n",
    "    # Define a grey RGB\n",
    "    bad = (230, 230, 230)\n",
    "    colors = []\n",
    "    if count == 1:\n",
    "        # If there is only one value, color it grey\n",
    "        colors.append('background-color: rgb(230,230,230)')\n",
    "    else:\n",
    "        for i, v in enumerate(ordered):\n",
    "            # Linear interpolation (lerp) between red and light green\n",
    "            r = int(good[0] + (bad[0] - good[0]) * (i / (count - 1)))\n",
    "            g = int(good[1] + (bad[1] - good[1]) * (i / (count - 1)))\n",
    "            b = int(good[2] + (bad[2] - good[2]) * (i / (count - 1)))\n",
    "            colors.append(f'background-color: rgb({r},{g},{b})')\n",
    "    \n",
    "    # Make best color even more vibrant\n",
    "    colors[0] = 'background-color: rgb(110, 235, 55)'\n",
    "    \n",
    "    # Assign colors to the original values based on their rank\n",
    "    styles = [colors[ordered.index.get_loc(i)] for i in s.index]\n",
    "    return styles\n",
    "\n",
    "\n",
    "# Apply the function along the DataFrame's columns\n",
    "styled_results = results.style.apply(grade_by_rank, axis=0)\n",
    "        \n",
    "styled_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
